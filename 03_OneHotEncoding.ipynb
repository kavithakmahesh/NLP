{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuu5HXaWLWSM"
      },
      "source": [
        "## One Hot Encoding of text\n",
        "\n",
        "This implements one hot encoding.\n",
        "\n",
        "In real world projects one mostly uses scikit -learnâ€™s implementation of one hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DhGNP6PQjrMT",
        "outputId": "35b922ef-dcdf-48cf-e2b2-b53ca98f82be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "# To install only the requirements of this notebook, uncomment the lines below and run this cell\n",
        "\n",
        "# ===========================\n",
        "\n",
        "!pip install scikit-learn\n",
        "\n",
        "# ==========================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Uw3jxJ0rjrMW"
      },
      "outputs": [],
      "source": [
        "# To install the requirements for the entire chapter, uncomment the lines below and run this cell\n",
        "\n",
        "# ===========================\n",
        "\n",
        "# try :\n",
        "#     import google.colab\n",
        "#     !curl https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch3/ch3-requirements.txt | xargs -n 1 -L 1 pip install\n",
        "# except ModuleNotFoundError :\n",
        "#     !pip install -r \"ch3-requirements.txt\"\n",
        "\n",
        "# ==========================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvndsBIzLWSQ",
        "outputId": "ecb23767-258d-4f64-9466-b27ce07694dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "documents = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"]\n",
        "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
        "processed_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWJcOZLBLWSW",
        "outputId": "6b30f5f6-e156-435f-ed0f-aed4deac54bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dog': 1, 'bites': 2, 'man': 3, 'eats': 4, 'meat': 5, 'food': 6}\n"
          ]
        }
      ],
      "source": [
        "#Build the vocabulary\n",
        "vocab = {}\n",
        "count = 0\n",
        "for doc in processed_docs:\n",
        "    for word in doc.split():\n",
        "        if word not in vocab:\n",
        "            count = count +1\n",
        "            vocab[word] = count\n",
        "print(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4pesdRwpLWSc"
      },
      "outputs": [],
      "source": [
        "#Get one hot representation for any string based on this vocabulary.\n",
        "#If the word exists in the vocabulary, its representation is returned.\n",
        "#If not, a list of zeroes is returned for that word.\n",
        "def get_onehot_vector(somestring):\n",
        "    onehot_encoded = []\n",
        "    for word in somestring.split():\n",
        "        temp = [0]*len(vocab)\n",
        "        if word in vocab:\n",
        "            temp[vocab[word]-1] = 1 # -1 is to take care of the fact indexing in array starts from 0 and not 1\n",
        "        onehot_encoded.append(temp)\n",
        "    return onehot_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JELqSh4gLWSg",
        "outputId": "6a50954a-4415-4a6c-8f8d-3768306bcad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "man bites dog\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "print(processed_docs[1])\n",
        "get_onehot_vector(processed_docs[1]) #one hot representation for a text from our corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVQExJUGLWSm",
        "outputId": "287db8d2-0473-45c7-c14a-6b650dec104a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "get_onehot_vector(\"man and dog are good\")\n",
        "#one hot representation for a random text, using the above vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xb8azVwLWSs",
        "outputId": "0e86f707-6094-4f2f-ccb5-711b94b56fc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "get_onehot_vector(\"man and man are good\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANj41SQ4L7xI"
      },
      "source": [
        "## One-hot encoding using scikit -learn\n",
        "##### We encode our corpus as a one-hot numeric array using scikit-learn's OneHotEncoder.\n",
        "##### We will demostrate:\n",
        "\n",
        "*   One Hot Encoding: In one-hot encoding, each word w in corpus vocabulary is given a unique integer id wid that is between 1 and |V|, where V is the set of corpus vocab. Each word is then represented by a V-dimensional binary vector of 0s and 1s.\n",
        "\n",
        "*   Label Encoding: In Label Encoding, each word w in our corpus is converted into a numeric value between 0 and n-1 (where n refers to number of unique words in our corpus).\n",
        "\n",
        "##### Link for the official documentation of both can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) and [here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) respectively.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sAPkk-fZLh4W"
      },
      "outputs": [],
      "source": [
        "S1 = 'dog bites man'\n",
        "S2 = 'man bites dog'\n",
        "S3 = 'dog eats meat'\n",
        "S4 = 'man eats food'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYCRHl5SLWSy",
        "outputId": "be1d2be3-0717-4a56-a8a5-092d915031e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The data:  ['dog', 'bites', 'man', 'man', 'bites', 'dog', 'dog', 'eats', 'meat', 'man', 'eats', 'food']\n",
            "Label Encoded: [1 0 4 4 0 1 1 2 5 4 2 3]\n",
            "Onehot Encoded Matrix:\n",
            " [[1. 0. 1. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 1. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 1. 0. 1. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "data = [S1.split(), S2.split(), S3.split(), S4.split()]\n",
        "values = data[0]+data[1]+data[2]+data[3]\n",
        "print(\"The data: \",values)\n",
        "\n",
        "#Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "print(\"Label Encoded:\",integer_encoded)\n",
        "\n",
        "#One-Hot Encoding\n",
        "onehot_encoder = OneHotEncoder()\n",
        "onehot_encoded = onehot_encoder.fit_transform(data).toarray()\n",
        "print(\"Onehot Encoded Matrix:\\n\",onehot_encoded)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "OneHotEncoding.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}